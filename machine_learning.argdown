===
title: >
  Machine learning arguments
author: Beau Sievers
date: 2021-01-18
color:
    colorScheme: colorbrewer-category9
    tagColors:
        pro: 0
        con: 1
        ambiv: 7
model:
    removeTagsFromText: true
webComponent:
    width: 75%
    height: 35em
===

The core question of machine learning is whether the benefits outweigh the risks. 

[Benefits outweigh risks]: The benefits of machine learning outweigh the risks.
    + <Technological advance>: Machine learning constitutes a major technological advance. #pro
    - <Serious risks>: Machine learning systems pose serious risks. #con

Arguments about whether machine learning constitutes a major technological advance.

<Technological advance>: Machine learning systems constitute a technological advance sufficient to outweigh the associated risks. #pro
    + <Impressive breakthroughs>: Machine learning systems outperform humans at [complex games like go](https://science.sciencemag.org/content/362/6419/1140/) and difficult tasks like [protein folding](https://www.nature.com/articles/s41586-019-1923-7). #pro
        - <Exaggerated results>: The performance of machine learning systems is exaggerated due to perverse incentives such as [publication bias](https://en.wikipedia.org/wiki/Publication_bias). #con
    + <Superhuman performance>: Machine learning systems [perform as well or better than humans](https://www.pnas.org/content/117/48/30033) on a wide range of tasks. #pro
        - <Data hungry>: Machine learning systems are sample-inefficient, requiring [extremely large training datasets](https://ieeexplore.ieee.org/abstract/document/4804817) in order to match human performance. #con
        - <Adversarial examples>: Machine learning systems are [easily fooled](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.html) by [adversarial examples](https://arxiv.org/abs/1312.6199) that do not fool humans. #con
        + <Good generalization>: Machine learning systems have [good generalization performance](https://arxiv.org/abs/1710.05468). #pro
            - <Poor generalization>
        - <Poor generalization>: Machine learning systems have trouble dealing with [input that is unlike the training data](https://www.sciencedirect.com/science/article/abs/pii/S0031320311002901). #con
            - <Good generalization>
        - <Difficult tasks>: Machine learning systems [perform poorly on tasks that are relatively easy for humans](https://arxiv.org/ftp/arxiv/papers/1801/1801.00631.pdf), like reasoning and understanding causality. #con
    + <Universal approximator>: Deep neural networks can [approximate any function](https://www.sciencedirect.com/science/article/abs/pii/089360809190009T). #pro
        _ <Difficult tasks>
    + <Cognitive modeling>: Machine learning systems are useful for [modeling human perception and cognition](https://www.annualreviews.org/doi/abs/10.1146/annurev-vision-082114-035447). #pro
        - <Difficult tasks>
        - <Adversarial examples>
        - <Data hungry>
    + <Labor-saving automation>: Machine learning systems [can automate human labor](https://www.jair.org/index.php/jair/article/view/11222). #pro
        _ <Job creation>
    + <Bias quantification>: Machine learning systems can [reveal](https://science.sciencemag.org/content/356/6334/183.abstract) and [quantify](https://www.pnas.org/content/115/16/E3635.short) human biases. #pro
        + <Humans are biased>
        + <Cognitive modeling>
    + <Human augmentation>: Machine learning systems can support and augment human [intelligence](https://distill.pub/2017/aia/) and [creativity](http://computationalcreativity.net/iccc2014/wp-content/uploads/2013/09/ComputationalCreativity.pdf). #pro
    - <Exaggerated results>
        - <Impressive breakthroughs>
    - <Energy inefficient>
    _ <Ambivalence toward technology>: Technological "advancement" or ["progress"](https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1292&context=tnas) is [not necessarily good](https://lib.anarhija.net/library/jacques-ellul-the-technological-society.pdf). #ambiv

Arguments about whether machine learning constitutes a serious risk.    

<Serious risks>: The risks posed by machine learning systems do not outweigh the benefits.
    + <Bias reproduction>: Machine learning systems can [reproduce and perpetuate harmful human biases](https://weaponsofmathdestructionbook.com/). #con
        + <Humans are biased>: [Human decision-making is biased](https://science.sciencemag.org/content/185/4157/1124.abstract) and [predjudice against minoritized people is pervasive](https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-071811-145508). #ambiv
        + <False objectivity>: The use of machine learning systems can create [a false sense of objectivity](https://link.springer.com/article/10.1007/s13347-017-0273-3) by [obscuring](https://arxiv.org/abs/2002.05193) or [inappropriately bracketing](https://dl.acm.org/doi/abs/10.1145/3351095.3372840) their limitations. #con
        - <De-biasing>: Machine learning systems can be [audited for bias](https://arxiv.org/abs/1810.01943) or [modified to reduce bias](https://papers.nips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html). #pro
            - <De-biasing doesn't work>: Model [de-biasing doesn't fully eliminate biases](https://arxiv.org/abs/1903.03862). #con
        - <Bias quantification>
    + <False objectivity>
    + <Black box>: People enjoy a [right to explanation of decisions that affect them](https://arxiv.org/abs/1606.08813), but it is [difficult to understand why machine learning systems make any given decision](https://arxiv.org/abs/1702.08608). #con
        _ <Human reasoning is also a black box>: It is also difficult to understand [why humans make any given decision](https://www.annualreviews.org/doi/full/10.1146/annurev.neuro.29.051605.113038). #ambiv
            _ <Humans are socially culpable>: [Humans are held to account by other humans, while machine learning systems cannot be.](https://mitpress.mit.edu/books/promise-artificial-intelligence) #ambiv
        - <Explainability>: Improving the [explainability](https://distill.pub/2018/building-blocks/) and [interpretability](https://arxiv.org/abs/1702.08608) of machine learning systems is an active research area. #pro
    _ <Precautionary principle>: The risks posed by machine learning systems can be mitigated by following [the precautionary principle](https://ehp.niehs.nih.gov/doi/abs/10.1289/ehp.01109871). #ambiv
        _ <Costs of precaution>: The precautionary princple [limits innovation and economic growth](https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence) #pro
    + <Surveillance state>: Machine learning systems facilitate the overreach and abuse of [government](https://www.nature.com/articles/d41586-020-03187-3) and [corporate](https://link.springer.com/article/10.1057/jit.2015.5) surveillance. #con
    + <Shaping humans to fit machines>: Owners of machine learning systems will [incentivize and coerce](https://journals.sagepub.com/doi/abs/10.1177/1527476418796632) people to shape their behavior to fit the constraints of machine learning systems. #con
        + <Lack of consent>: Human-generated training data are often [collected and used without consent](https://journals.sagepub.com/doi/full/10.1177/2053951716650211). #con
        + <Dependence on human labor>
        + <Data hungry>
    + <Economic disruption>: [People could be pushed out of their jobs by machine learning systems](https://www.sciencedirect.com/science/article/pii/S0040162516302244) causing [increasing in inequaltiy](https://www.aeaweb.org/articles?id=10.1257/pandp.20201063). #con
        + <Labor-saving automation>
        - <Job creation>: Historically, [automation has resulted in job creation](https://www.aeaweb.org/articles?id=10.1257%2Fjep.29.3.3) that offsets job loss. #pro
            + <Dependence on human labor>: The production and labeling of training data depends on [(often invisible) human labor](https://ghostwork.info/). #con
                + <Data hungry>
            _ <Bullshit jobs>: We should not want to create more [bullshit jobs](https://www.simonandschuster.com/books/Bullshit-Jobs/David-Graeber/9781501143335). #ambiv
    + <Energy inefficient>: Training large machine learning models is [energy inefficient](https://arxiv.org/abs/1906.02243) and contributes to climate change. #con
    + <Superintelligence is an existential threat>: A sufficiently intelligent machine may [destroy humanity](http://jetpress.org/volume9/risks.html) #con
        - <Safety research>: [Safety risks posed by intelligent machines](https://arxiv.org/abs/1606.06565) are an active research area. #pro
        - <Implausibility of superintelligence>: "Superintelligence" is [implausible](http://kryten.mm.rpi.edu/SB_singularity_math_final.pdf) or [not a threat](https://jetpress.org/v25.2/goertzel.pdf). #ambiv

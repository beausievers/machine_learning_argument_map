<!doctype html><html lang="en"><head><meta charset="utf8"><title>Machine learning arguments
</title><link rel="stylesheet" href="./argdown.css"><style>.tag-pro{color: #66c2a5;}
.tag-con{color: #fc8d62;}
.tag-ambiv{color: #b3b3b3;}
</style></head><body><div class="argdown"><header><h1>Machine learning arguments
</h1><div class="authors"><span class="author">Beau Sievers</></div><div class="date">Sun Jan 17 2021 16:00:00 GMT-0800 (Pacific Standard Time)</div></header><div data-line="38" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">This document maps arguments for and against machine learning.</span></b> I assume that machine learning systems constitute a major technological advance, but that the benefits ought to be weighed against a number of serious risks.</span></div><div data-line="40" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">Above, the arguments and connections between them are mapped.</span></b> Clicking on the map activates zoom and pan controls. To zoom the map, use the mouse-wheel or a two-finger scrolling gesture. To pan the map, click and drag the mouse. Green boxes represent &quot;pro&quot; arguments (for machine learning), while red boxes represent &quot;con&quot; arguments (against machine learning), and grey boxes represent arguments that are ambivalent. Blue arrows indicate support, red arrows indicate attack, and purple arrows indicate undermining.</span></div><div data-line="42" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">Below, each argument is explicated by a short text with links to supporting documentation.</span></b> Links were selected to offer a useful starting point for exploring each argument. But because the literature on many of the arguments is vast, no attempt has been made to be comprehensive. </span></div><div data-line="44" class="statement has-line top-level"><span class="statement-content top-level">The source code for this project is <a href="https://github.com/beausievers/machine_learning_argument_map">available on GitHub</a>. The map was constructed using <a href="https://argdown.org/">Argdown</a>.</span></div><div data-line="46" class="statement has-line top-level"><span id="statement-benefits-outweigh-risks" class="definition statement-definition definiendum top-level">[<span class="title statement-title">Benefits outweigh risks</span>]: </span><span class="statement-content top-level">The benefits of machine learning outweigh the risks.</span><div class="relations"><div data-line="47" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="47" class="argument has-line tag-pro"><a id="argument-technological-advance" href="#argument-technological-advance" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Technological advance</span>&gt;: </a><span class="statement-content">Machine learning constitutes a major technological advance. </span></div></div><div data-line="48" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="48" class="argument has-line tag-con"><a id="argument-serious-risks" href="#argument-serious-risks" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt;: </a><span class="statement-content">Machine learning systems pose serious risks. </span></div></div></div></div><div data-line="50" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">Next, we consider arguments that machine learning constitutes a major technological advance.</span></b></span></div><div data-line="52" class="statement has-line top-level"><span class="statement-content top-level">The main argument in favor of machine learning is that it supports <b><span class="statement-content">moral ends,</span></b> such as advancing scientific and technological progress, creating a more just society, saving labor, or enriching lived experience.</span></div><div data-line="54" class="argument has-line tag-pro top-level"><a id="argument-technological-advance-occurrence-2" href="#argument-technological-advance" class="definition argument-definition definiendum top-level tag-pro">&lt;<span class="title argument-title">Technological advance</span>&gt;: </a><span class="statement-content top-level">Machine learning systems constitute a technological advance sufficient to outweigh the associated risks. Machine learning systems outperform humans at <a href="https://science.sciencemag.org/content/362/6419/1140/">complex games like go</a>, difficult tasks like <a href="https://www.nature.com/articles/s41586-019-1923-7">protein folding</a>, and <a href="https://www.pnas.org/content/117/48/30033">more</a>. </span><div class="relations"><div data-line="55" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="55" class="argument has-line tag-pro"><a id="argument-universal-approximator" href="#argument-universal-approximator" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Universal approximator</span>&gt;: </a><span class="statement-content">Deep neural networks can <a href="https://www.sciencedirect.com/science/article/abs/pii/089360809190009T">approximate any function</a>. </span></div></div><div data-line="56" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="56" class="argument has-line tag-pro"><a id="argument-cognitive-modeling" href="#argument-cognitive-modeling" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt;: </a><span class="statement-content">Machine learning systems are useful for <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-vision-082114-035447">modeling human perception and cognition</a>. </span></div></div><div data-line="57" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="57" class="argument has-line tag-pro"><a id="argument-bias-quantification" href="#argument-bias-quantification" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Bias quantification</span>&gt;: </a><span class="statement-content">Machine learning systems can <a href="https://science.sciencemag.org/content/356/6334/183.abstract">reveal</a> and <a href="https://www.pnas.org/content/115/16/E3635.short">quantify</a> human biases. </span><div class="relations"><div data-line="58" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="58" class="argument has-line tag-ambiv"><a id="" href="#argument-humans-are-biased" data-line="58" class="has-line reference argument-reference tag-ambiv">&lt;<span class="title argument-title">Humans are biased</span>&gt; </a></div></div><div data-line="59" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="59" class="argument has-line tag-pro"><a id="" href="#argument-cognitive-modeling" data-line="59" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt; </a></div></div></div></div></div><div data-line="60" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="60" class="argument has-line"><a id="argument-algorithmic-fairness" href="#argument-algorithmic-fairness" class="definition argument-definition definiendum">&lt;<span class="title argument-title">Algorithmic fairness</span>&gt;: </a><span class="statement-content">Algorithms can be designed to make <a href="https://dl.acm.org/doi/abs/10.1145/3097983.3098095">fair</a> and <a href="https://papers.nips.cc/paper/2017/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html">equitable</a> decisions.</span><div class="relations"><div data-line="61" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="61" class="argument has-line tag-pro"><a id="" href="#argument-bias-quantification" data-line="61" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Bias quantification</span>&gt; </a></div></div><div data-line="62" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="62" class="argument has-line tag-con"><a id="" href="#argument-false-objectivity" data-line="62" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">False objectivity</span>&gt; </a></div></div></div></div></div><div data-line="63" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="63" class="argument has-line tag-pro"><a id="argument-labor-saving-automation" href="#argument-labor-saving-automation" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Labor-saving automation</span>&gt;: </a><span class="statement-content">Machine learning systems <a href="https://www.jair.org/index.php/jair/article/view/11222">can automate human labor</a>. </span><div class="relations"><div data-line="64" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="64" class="argument has-line tag-pro"><a id="" href="#argument-job-creation" data-line="64" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Job creation</span>&gt; </a></div></div></div></div></div><div data-line="65" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="65" class="argument has-line tag-pro"><a id="argument-human-augmentation" href="#argument-human-augmentation" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Human augmentation</span>&gt;: </a><span class="statement-content">Machine learning systems can support and augment human <a href="https://distill.pub/2017/aia/">intelligence</a> and <a href="http://computationalcreativity.net/iccc2014/wp-content/uploads/2013/09/ComputationalCreativity.pdf">creativity</a>. </span></div></div></div></div><div data-line="67" class="statement has-line top-level"><span class="statement-content top-level">However, these <b><span class="statement-content">purported breakthroughs might not be impressive as they seem.</span></b> From a social perspective, perverse incentives might lead us to doubt the veracity of claims made by advocates of machine learning. From a technical perspective, the use of machine learning systems clearly has substantial drawbacks. Such systems require massive amounts of data, and are often brittle and fail to generalize. From a theoretical perspective, machine learning systems have trouble with tasks that are relatively easy for humans, casting doubt on claims for their superiority.</span></div><div data-line="69" class="argument has-line tag-pro top-level"><a id="" href="#argument-technological-advance" data-line="69" class="has-line reference argument-reference top-level tag-pro">&lt;<span class="title argument-title">Technological advance</span>&gt; </a> <div class="relations"><div data-line="70" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="70" class="argument has-line tag-con"><a id="argument-exaggerated-results" href="#argument-exaggerated-results" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Exaggerated results</span>&gt;: </a><span class="statement-content">The performance of machine learning systems is exaggerated due to perverse incentives such as <a href="https://en.wikipedia.org/wiki/Publication_bias">publication bias</a>. </span><div class="relations"><div data-line="71" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="71" class="argument has-line tag-pro"><a id="" href="#argument-technological-advance" data-line="71" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Technological advance</span>&gt; </a></div></div></div></div></div><div data-line="72" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="72" class="argument has-line tag-con"><a id="argument-data-hungry" href="#argument-data-hungry" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Data hungry</span>&gt;: </a><span class="statement-content">Machine learning systems are sample-inefficient, requiring <a href="https://ieeexplore.ieee.org/abstract/document/4804817">extremely large training datasets</a> in order to match human performance. </span><div class="relations"><div data-line="73" class="has-line incoming attack relation"><div class="incoming attack relation-symbol"><span>-&gt;</span></div><div data-line="73" class="argument has-line tag-pro"><a id="" href="#argument-cognitive-modeling" data-line="73" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt; </a></div></div></div></div></div><div data-line="74" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="74" class="argument has-line tag-con"><a id="argument-poor-generalization" href="#argument-poor-generalization" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Poor generalization</span>&gt;: </a><span class="statement-content">Machine learning systems have trouble dealing with <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320311002901">input that is unlike the training data</a>. </span><div class="relations"><div data-line="75" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="75" class="argument has-line tag-pro"><a id="argument-good-generalization" href="#argument-good-generalization" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Good generalization</span>&gt;: </a><span class="statement-content">Machine learning systems have <a href="https://arxiv.org/abs/1710.05468">good generalization performance</a>. </span><div class="relations"><div data-line="76" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="76" class="argument has-line tag-con"><a id="" href="#argument-poor-generalization" data-line="76" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Poor generalization</span>&gt; </a></div></div><div data-line="77" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="77" class="argument has-line tag-pro"><a id="" href="#argument-cognitive-modeling" data-line="77" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt; </a></div></div></div></div></div><div data-line="78" class="has-line incoming attack relation"><div class="incoming attack relation-symbol"><span>-&gt;</span></div><div data-line="78" class="argument has-line tag-pro"><a id="" href="#argument-cognitive-modeling" data-line="78" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt; </a></div></div></div></div></div><div data-line="79" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="79" class="argument has-line tag-con"><a id="argument-adversarial-examples" href="#argument-adversarial-examples" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Adversarial examples</span>&gt;: </a><span class="statement-content">Machine learning systems are <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.html">easily fooled</a> by <a href="https://arxiv.org/abs/1312.6199">adversarial examples</a> that do not fool humans. </span><div class="relations"><div data-line="80" class="has-line incoming attack relation"><div class="incoming attack relation-symbol"><span>-&gt;</span></div><div data-line="80" class="argument has-line tag-pro"><a id="" href="#argument-cognitive-modeling" data-line="80" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt; </a></div></div></div></div></div><div data-line="81" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="81" class="argument has-line tag-con"><a id="argument-difficult-tasks" href="#argument-difficult-tasks" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Difficult tasks</span>&gt;: </a><span class="statement-content">Machine learning systems <a href="https://arxiv.org/ftp/arxiv/papers/1801/1801.00631.pdf">perform poorly on tasks that are relatively easy for humans</a>, like reasoning and understanding causality. </span><div class="relations"><div data-line="82" class="has-line incoming undercut relation"><div class="incoming undercut relation-symbol"><span>_&gt;</span></div><div data-line="82" class="argument has-line tag-pro"><a id="" href="#argument-universal-approximator" data-line="82" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Universal approximator</span>&gt; </a></div></div><div data-line="83" class="has-line incoming attack relation"><div class="incoming attack relation-symbol"><span>-&gt;</span></div><div data-line="83" class="argument has-line tag-pro"><a id="" href="#argument-cognitive-modeling" data-line="83" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Cognitive modeling</span>&gt; </a></div></div></div></div></div></div></div><div data-line="85" class="statement has-line top-level"><span class="statement-content top-level">Finally, claims in favor of machine learning may be undermined by arguments that <b><span class="statement-content">technological advancement is morally ambivalent</span></b> or undesirable, or that the the very concepts of technological &quot;progress&quot; or &quot;advancement&quot; are incoherent.</span></div><div data-line="87" class="argument has-line tag-pro top-level"><a id="" href="#argument-technological-advance" data-line="87" class="has-line reference argument-reference top-level tag-pro">&lt;<span class="title argument-title">Technological advance</span>&gt; </a> <div class="relations"><div data-line="88" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="88" class="argument has-line tag-ambiv"><a id="argument-ambivalence-toward-technology" href="#argument-ambivalence-toward-technology" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Ambivalence toward technology</span>&gt;: </a><span class="statement-content">Technological &quot;advancement&quot; or <a href="https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1292&context=tnas">"progress"</a> is <a href="https://lib.anarhija.net/library/jacques-ellul-the-technological-society.pdf">not necessarily good</a>. </span></div></div></div></div><div data-line="90" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">Below, we consider arguments that machine learning constitutes a serious risk.</span></b></span></div><div data-line="92" class="statement has-line top-level"><span class="statement-content top-level">The benefits of machine learning must be balanced against a range of serious risks. Because machine learning poses many risks, we address these arguments in groups, roughly organized by conceptual similarity.</span></div><div data-line="94" class="statement has-line top-level"><span class="statement-content top-level">First, machine learning systems can support <b><span class="statement-content">immoral ends</span></b> just as effectively as moral ones. For example, accurate face recognition technology supports the expansion of the surveillance state. The effectiveness of machine could therefore lead to a concentration of power in the hands of those who can afford to use it, risking the erosion of personal freedom and civil liberties. </span></div><div data-line="96" class="argument has-line tag-con top-level"><a id="argument-serious-risks-occurrence-2" href="#argument-serious-risks" class="definition argument-definition definiendum top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt;: </a><span class="statement-content top-level">The risks posed by machine learning systems do not outweigh the benefits.</span><div class="relations"><div data-line="97" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="97" class="argument has-line tag-con"><a id="argument-surveillance-state" href="#argument-surveillance-state" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Surveillance state</span>&gt;: </a><span class="statement-content">Machine learning systems facilitate the overreach and abuse of <a href="https://www.nature.com/articles/d41586-020-03187-3">government</a> and <a href="https://link.springer.com/article/10.1057/jit.2015.5">corporate</a> surveillance. </span><div class="relations"><div data-line="98" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="98" class="argument has-line tag-con"><a id="" href="#argument-concentration-of-power" data-line="98" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Concentration of power</span>&gt; </a></div></div><div data-line="99" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="99" class="argument has-line tag-con"><a id="" href="#argument-behavioral-control" data-line="99" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Behavioral control</span>&gt; </a></div></div></div></div></div><div data-line="100" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="100" class="argument has-line tag-con"><a id="argument-behavioral-control" href="#argument-behavioral-control" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Behavioral control</span>&gt;: </a><span class="statement-content">Owners of machine learning systems will <a href="https://journals.sagepub.com/doi/abs/10.1177/1527476418796632">incentivize and coerce</a> people to shape their behavior to provide data for and fit the constraints of machine learning systems. Further, machine learning systems can be used to cheaply produce <a href="https://arxiv.org/abs/2009.06807">propaganda at scale</a>. </span><div class="relations"><div data-line="101" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="101" class="argument has-line tag-con"><a id="" href="#argument-dependence-on-human-labor" data-line="101" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Dependence on human labor</span>&gt; </a></div></div><div data-line="102" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="102" class="argument has-line tag-con"><a id="" href="#argument-surveillance-state" data-line="102" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Surveillance state</span>&gt; </a></div></div></div></div></div><div data-line="103" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="103" class="argument has-line tag-con"><a id="argument-concentration-of-power" href="#argument-concentration-of-power" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Concentration of power</span>&gt;: </a><span class="statement-content">The expense of machine learning <a href="https://arxiv.org/abs/2010.15581">concentrates power in large, wealthy organizations</a>. </span><div class="relations"><div data-line="104" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="104" class="argument has-line tag-con"><a id="" href="#argument-behavioral-control" data-line="104" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Behavioral control</span>&gt; </a></div></div></div></div></div><div data-line="105" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="105" class="argument has-line tag-con"><a id="argument-lack-of-consent" href="#argument-lack-of-consent" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Lack of consent</span>&gt;: </a><span class="statement-content">Human-generated training data are often <a href="https://journals.sagepub.com/doi/full/10.1177/2053951716650211">collected and used without consent</a>. </span><div class="relations"><div data-line="106" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="106" class="argument has-line tag-con"><a id="" href="#argument-behavioral-control" data-line="106" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Behavioral control</span>&gt; </a></div></div><div data-line="107" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="107" class="argument has-line tag-con"><a id="" href="#argument-dependence-on-human-labor" data-line="107" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Dependence on human labor</span>&gt; </a></div></div></div></div></div></div></div><div data-line="109" class="statement has-line top-level"><span class="statement-content top-level">Machine learning systems can exacerbate <b><span class="statement-content">injustices and social inequalities.</span></b> Because machine learning systems are sensitive to both explicit and implicit biases, they can easily reproduce and exacerbate those biases when deployed in consumer products or institutional decision-making tools. Although techniques for mitigating bias are an active research area, these techniques are not necessarily effective. Minoritized people who are already subject to human biases stand to be harmed the most when these biases are reproduced by machine learning systems. Further, because machine learning systems require large amounts of training data, minority communities often cannot reap the benefits of machine learning systems even as they are subject to their harms.</span></div><div data-line="111" class="argument has-line tag-con top-level"><a id="" href="#argument-serious-risks" data-line="111" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a> <div class="relations"><div data-line="112" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="112" class="argument has-line tag-con"><a id="argument-bias-reproduction" href="#argument-bias-reproduction" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Bias reproduction</span>&gt;: </a><span class="statement-content">Machine learning systems can <a href="https://weaponsofmathdestructionbook.com/">reproduce and perpetuate harmful human biases</a>. </span><div class="relations"><div data-line="113" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="113" class="argument has-line tag-ambiv"><a id="argument-humans-are-biased" href="#argument-humans-are-biased" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Humans are biased</span>&gt;: </a><span class="statement-content"><a href="https://science.sciencemag.org/content/185/4157/1124.abstract">Human decision-making is biased</a> and <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-071811-145508">predjudice against minoritized people is pervasive</a>. </span></div></div><div data-line="114" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="114" class="argument has-line tag-con"><a id="" href="#argument-minority-exclusion" data-line="114" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Minority exclusion</span>&gt; </a></div></div><div data-line="115" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="115" class="argument has-line tag-pro"><a id="argument-de-biasing" href="#argument-de-biasing" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">De-biasing</span>&gt;: </a><span class="statement-content">Machine learning systems can be <a href="https://arxiv.org/abs/1810.01943">audited for bias</a> or <a href="https://papers.nips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html">modified to reduce bias</a>. </span><div class="relations"><div data-line="116" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="116" class="argument has-line tag-con"><a id="argument-de-biasing-doesnt-work" href="#argument-de-biasing-doesnt-work" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">De-biasing doesn't work</span>&gt;: </a><span class="statement-content">Model <a href="https://arxiv.org/abs/1903.03862">de-biasing doesn't fully eliminate biases</a>. </span></div></div></div></div></div><div data-line="117" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="117" class="argument has-line"><a id="" href="#argument-algorithmic-fairness" data-line="117" class="has-line reference argument-reference">&lt;<span class="title argument-title">Algorithmic fairness</span>&gt; </a></div></div></div></div></div><div data-line="118" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="118" class="argument has-line tag-con"><a id="argument-minority-exclusion" href="#argument-minority-exclusion" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Minority exclusion</span>&gt;: </a><span class="statement-content">Cultural contexts that are smaller are more difficult to mine for training data, resulting in <a href="https://arxiv.org/abs/2003.11529">exclusion from machine learning systems</a>. </span><div class="relations"><div data-line="119" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="119" class="argument has-line tag-ambiv"><a id="argument-ambivalence-of-minority-representation" href="#argument-ambivalence-of-minority-representation" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Ambivalence of minority representation</span>&gt;: </a><span class="statement-content"><a href="https://digitaltalkingdrum.com/2017/08/15/against-black-inclusion-in-facial-recognition/">Minority representation can support discrimination</a>, and is therefore not always desirable. </span></div></div></div></div></div></div></div><div data-line="121" class="statement has-line top-level"><span class="statement-content top-level">A related risk is that of <b><span class="statement-content">false objectivity.</span></b> When a decision is made by a machine learning system, it can falsely appear to be objectively correct, as opposed to the product of falliable human judgment. This mistake overlooks the the role of human bias in the production of training data, the design of the algorithm, and the goals of the system.</span></div><div data-line="123" class="argument has-line tag-con top-level"><a id="" href="#argument-serious-risks" data-line="123" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a> <div class="relations"><div data-line="124" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="124" class="argument has-line tag-con"><a id="argument-false-objectivity" href="#argument-false-objectivity" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">False objectivity</span>&gt;: </a><span class="statement-content">The use of machine learning systems can create <a href="https://link.springer.com/article/10.1007/s13347-017-0273-3">a false sense of objectivity</a> by <a href="https://arxiv.org/abs/2002.05193">obscuring</a> or <a href="https://dl.acm.org/doi/abs/10.1145/3351095.3372840">inappropriately bracketing</a> their limitations. </span><div class="relations"><div data-line="125" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="125" class="argument has-line tag-con"><a id="" href="#argument-bias-reproduction" data-line="125" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Bias reproduction</span>&gt; </a></div></div><div data-line="126" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="126" class="argument has-line tag-con"><a id="" href="#argument-minority-exclusion" data-line="126" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Minority exclusion</span>&gt; </a></div></div><div data-line="127" class="has-line incoming attack relation"><div class="incoming attack relation-symbol"><span>-&gt;</span></div><div data-line="127" class="argument has-line tag-pro"><a id="" href="#argument-de-biasing" data-line="127" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">De-biasing</span>&gt; </a></div></div></div></div></div></div></div><div data-line="129" class="statement has-line top-level"><span class="statement-content top-level">Machine learning systems are <b><span class="statement-content">difficult to understand.</span></b> Using such systems in applications such as medicine, insurance, etc., therefore poses a serious problem, as people have the right to the explanation of decisions that affect their lives. For this reason, explainable and interpretable machine learning systems are an active research area. One objection to this argument is that human explanations are also opaque, and are therefore no better. However, we may trust human judgments because they are underwritten by webs of social sanction and support, whereas machine learning systems are not.</span></div><div data-line="131" class="argument has-line tag-con top-level"><a id="" href="#argument-serious-risks" data-line="131" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a> <div class="relations"><div data-line="132" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="132" class="argument has-line tag-con"><a id="argument-black-box" href="#argument-black-box" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Black box</span>&gt;: </a><span class="statement-content">People enjoy a <a href="https://arxiv.org/abs/1606.08813">right to explanation of decisions that affect them</a>, but it is <a href="https://arxiv.org/abs/1702.08608">difficult to understand why machine learning systems make any given decision</a>. </span><div class="relations"><div data-line="133" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="133" class="argument has-line tag-ambiv"><a id="argument-human-reasoning-is-also-a-black-box" href="#argument-human-reasoning-is-also-a-black-box" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Human reasoning is also a black box</span>&gt;: </a><span class="statement-content">It is also difficult to understand <a href="https://www.annualreviews.org/doi/full/10.1146/annurev.neuro.29.051605.113038">why humans make any given decision</a>. </span><div class="relations"><div data-line="134" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="134" class="argument has-line tag-ambiv"><a id="argument-humans-are-socially-culpable" href="#argument-humans-are-socially-culpable" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Humans are socially culpable</span>&gt;: </a><span class="statement-content"><a href="https://mitpress.mit.edu/books/promise-artificial-intelligence">Humans are held to account by other humans, while machine learning systems cannot be.</a> </span></div></div></div></div></div><div data-line="135" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="135" class="argument has-line tag-pro"><a id="argument-explainability" href="#argument-explainability" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Explainability</span>&gt;: </a><span class="statement-content">Improving the <a href="https://distill.pub/2018/building-blocks/">explainability</a> and <a href="https://arxiv.org/abs/1702.08608">interpretability</a> of machine learning systems is an active research area. </span></div></div></div></div></div></div></div><div data-line="137" class="statement has-line top-level"><span class="statement-content top-level">The success of machine learning systems may pose <b><span class="statement-content">economic risks.</span></b> The flipside of labor-saving automation is job loss, which could exacerbate the concentration of power in organizations that can afford machine learning systems. Historically, however, job loss due to automation has been offset by the creation of new jobs. For machine learning, these jobs would likely involve the creation and maintence of large training datasets. However, such labor is often low-status and underpaid, and we may not want to create such jobs if they pointless and unfulfilling.</span></div><div data-line="139" class="argument has-line tag-con top-level"><a id="" href="#argument-serious-risks" data-line="139" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a> <div class="relations"><div data-line="140" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="140" class="argument has-line tag-con"><a id="argument-economic-disruption" href="#argument-economic-disruption" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Economic disruption</span>&gt;: </a><span class="statement-content"><a href="https://www.sciencedirect.com/science/article/pii/S0040162516302244">People could be pushed out of their jobs by machine learning systems</a> causing <a href="https://www.aeaweb.org/articles?id=10.1257/pandp.20201063">increasing inequaltiy</a>. </span><div class="relations"><div data-line="141" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="141" class="argument has-line tag-pro"><a id="" href="#argument-labor-saving-automation" data-line="141" class="has-line reference argument-reference tag-pro">&lt;<span class="title argument-title">Labor-saving automation</span>&gt; </a></div></div><div data-line="142" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="142" class="argument has-line tag-pro"><a id="argument-job-creation" href="#argument-job-creation" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Job creation</span>&gt;: </a><span class="statement-content">Historically, <a href="https://www.aeaweb.org/articles?id=10.1257%2Fjep.29.3.3">automation has resulted in job creation</a> that offsets job loss. </span><div class="relations"><div data-line="143" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="143" class="argument has-line tag-con"><a id="argument-dependence-on-human-labor" href="#argument-dependence-on-human-labor" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Dependence on human labor</span>&gt;: </a><span class="statement-content">The production and labeling of training data depends on <a href="https://ghostwork.info/">(often invisible) human labor</a>. </span></div></div><div data-line="144" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="144" class="argument has-line tag-ambiv"><a id="argument-bullshit-jobs" href="#argument-bullshit-jobs" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Bullshit jobs</span>&gt;: </a><span class="statement-content">We should not want to create more <a href="https://www.simonandschuster.com/books/Bullshit-Jobs/David-Graeber/9781501143335">bullshit jobs</a>. </span></div></div></div></div></div><div data-line="145" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="145" class="argument has-line tag-con"><a id="" href="#argument-concentration-of-power" data-line="145" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Concentration of power</span>&gt; </a></div></div></div></div></div></div></div><div data-line="147" class="statement has-line top-level"><span class="statement-content top-level">Machine learning systems require <b><span class="statement-content">huge amounts of data,</span></b> and a number of risks lie downstream from this technological limitation. These risks include many of those discussed above, as well as the risk of energy inefficient machine learning systems exacerbating climate change.</span></div><div data-line="149" class="argument has-line tag-con top-level"><a id="" href="#argument-data-hungry" data-line="149" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Data hungry</span>&gt; </a> <div class="relations"><div data-line="150" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="150" class="argument has-line tag-con"><a id="argument-energy-inefficient" href="#argument-energy-inefficient" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Energy inefficient</span>&gt;: </a><span class="statement-content">Training large machine learning models is <a href="https://arxiv.org/abs/1906.02243">energy inefficient</a> and contributes to climate change. </span><div class="relations"><div data-line="151" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="151" class="argument has-line tag-con"><a id="" href="#argument-serious-risks" data-line="151" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a></div></div></div></div></div><div data-line="152" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="152" class="argument has-line tag-con"><a id="" href="#argument-dependence-on-human-labor" data-line="152" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Dependence on human labor</span>&gt; </a></div></div><div data-line="153" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="153" class="argument has-line tag-con"><a id="" href="#argument-minority-exclusion" data-line="153" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Minority exclusion</span>&gt; </a></div></div><div data-line="154" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="154" class="argument has-line tag-con"><a id="" href="#argument-lack-of-consent" data-line="154" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Lack of consent</span>&gt; </a></div></div><div data-line="155" class="has-line incoming support relation"><div class="incoming support relation-symbol"><span>+&gt;</span></div><div data-line="155" class="argument has-line tag-con"><a id="" href="#argument-concentration-of-power" data-line="155" class="has-line reference argument-reference tag-con">&lt;<span class="title argument-title">Concentration of power</span>&gt; </a></div></div></div></div><div data-line="157" class="statement has-line top-level"><span class="statement-content top-level">If artificially intelligent agents are smarter than humans but do not share human goals, they may pose an <b><span class="statement-content">existential risk.</span></b> However,superintelligence of this type may be conceptually or physically implausible, or the threat may be overstated. Such safety risks are an area of active research.</span></div><div data-line="159" class="argument has-line tag-con top-level"><a id="" href="#argument-serious-risks" data-line="159" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a> <div class="relations"><div data-line="160" class="has-line outgoing support relation"><div class="outgoing support relation-symbol"><span>+</span></div><div data-line="160" class="argument has-line tag-con"><a id="argument-superintelligence-is-an-existential-threat" href="#argument-superintelligence-is-an-existential-threat" class="definition argument-definition definiendum tag-con">&lt;<span class="title argument-title">Superintelligence is an existential threat</span>&gt;: </a><span class="statement-content">A sufficiently intelligent machine may <a href="http://jetpress.org/volume9/risks.html">destroy humanity</a> </span><div class="relations"><div data-line="161" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="161" class="argument has-line tag-pro"><a id="argument-safety-research" href="#argument-safety-research" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Safety research</span>&gt;: </a><span class="statement-content"><a href="https://arxiv.org/abs/1606.06565">Safety risks posed by intelligent machines</a> are an active research area. </span></div></div><div data-line="162" class="has-line outgoing attack relation"><div class="outgoing attack relation-symbol"><span>-</span></div><div data-line="162" class="argument has-line tag-ambiv"><a id="argument-implausibility-of-superintelligence" href="#argument-implausibility-of-superintelligence" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Implausibility of superintelligence</span>&gt;: </a><span class="statement-content">&quot;Superintelligence&quot; is <a href="http://kryten.mm.rpi.edu/SB_singularity_math_final.pdf">implausible</a> or <a href="https://jetpress.org/v25.2/goertzel.pdf">not a threat</a>. </span></div></div></div></div></div></div></div><div data-line="164" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">Below, we consider proposed means of mitigating these risks.</span></b></span></div><div data-line="166" class="statement has-line top-level"><span class="statement-content top-level">The risks of machine learning systems may be mitigated by following <b><span class="statement-content">the precautionary principle:</span></b> take care to limit potential risks even if the magnitude of those risks is unknown. Critics of this approach argue that the precautionary principle stifles innovation.</span></div><div data-line="168" class="argument has-line tag-con top-level"><a id="" href="#argument-serious-risks" data-line="168" class="has-line reference argument-reference top-level tag-con">&lt;<span class="title argument-title">Serious risks</span>&gt; </a> <div class="relations"><div data-line="169" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="169" class="argument has-line tag-ambiv"><a id="argument-precautionary-principle" href="#argument-precautionary-principle" class="definition argument-definition definiendum tag-ambiv">&lt;<span class="title argument-title">Precautionary principle</span>&gt;: </a><span class="statement-content">The risks posed by machine learning systems can be mitigated by following <a href="https://ehp.niehs.nih.gov/doi/abs/10.1289/ehp.01109871">the precautionary principle</a>. </span><div class="relations"><div data-line="170" class="has-line outgoing undercut relation"><div class="outgoing undercut relation-symbol"><span>&lt;_</span></div><div data-line="170" class="argument has-line tag-pro"><a id="argument-costs-of-precaution" href="#argument-costs-of-precaution" class="definition argument-definition definiendum tag-pro">&lt;<span class="title argument-title">Costs of precaution</span>&gt;: </a><span class="statement-content">The precautionary princple <a href="https://itif.org/publications/2019/02/04/ten-ways-precautionary-principle-undermines-progress-artificial-intelligence">limits innovation and economic growth</a> </span></div></div></div></div></div></div></div><div data-line="172" class="statement has-line top-level"><span class="statement-content top-level"><b><span class="statement-content">Acknowledgements.</span></b> Thanks to Ted Underwood, Kevin Lin, Chris Beiser, Jackie Ess, Juan Ortiz Freuler, and Twitter user @muranava for helpful feedback.</span></div></div></body></html>